	# -*- coding: utf-8 -*-
"""functions.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SZP_RIpA9fK_7fFXPyQQSTAPSLkSXVAJ
"""

import warnings
warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt
from matplotlib.pyplot import figure
import seaborn as sns
import pandas as pd
import numpy as np
from numpy import sort
import yfinance as yf
import pandas_ta as ta
from fredapi import Fred
import pandas_datareader.data as web
import math

import tensorflow as tf
import keras_tuner as kt
from tensorflow import keras
from tensorflow.keras import layers, Sequential
from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Bidirectional, GRU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.metrics import RootMeanSquaredError
from keras import optimizers, Sequential
from keras.models import Model
from keras.utils import plot_model
from keras.layers import Dense, Flatten, LSTM, RepeatVector, TimeDistributed
from keras.callbacks import ModelCheckpoint, TensorBoard
from keras_tuner import HyperModel
from kerastuner.tuners import BayesianOptimization
from scikeras.wrappers import KerasClassifier

from sklearn.metrics import r2_score, mean_squared_error
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split

from sklearn.feature_selection import SelectFromModel
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.metrics.pairwise import nan_euclidean_distances
from sklearn.impute import KNNImputer

import xgboost as xg

def download_yahoo_finance(symbols, start_date, end_date):
  df = yf.download(symbols)
  df = df[(df.index >= start_date) & (df.index <= end_date)]
  df = df.dropna()
  return df

# Define functions
def wrangle_fred(id, start, end):
  start_date = start
  end_date = end
  fred_data = web.DataReader(id, 'fred', start_date, end_date)
  fred_data = fred_data.reset_index()
  fred_data.rename(columns={'DATE':'Date'}, inplace = True)
  fred_data = fred_data.set_index('Date')
  fred_data.index = pd.to_datetime(fred_data.index)
  return fred_data

def flip_dataframe(df):
    return df.iloc[::-1].reset_index(drop=False)


def lag_data(df):
    df_copy = df.copy()
    for column in df_copy.columns:
        df_copy[f'{column}_lag1'] = df_copy[column].pct_change()
    return df_copy

def high_correlation(df, column, threshold=0.5):
    # Compute the correlation matrix
    correlation_matrix = df.corr()

    # Get the correlations with the target column and sort them in descending order
    close_corr = correlation_matrix[column].sort_values(ascending=False)

    # Filter to only return correlations above the specified threshold
    high_corr = close_corr[close_corr.abs() > threshold]

    # Display the high correlation table
    print(f'High Correlation with {column}:')
    return high_corr


def calculate_indicators(df):
    # 1. Momentum Indicators
    ## Return
    df['Return_lag10'] = df['Close'].pct_change(10)

    ## Relative Strength Index (RSI) for different periods (14, 6, 5)
    df['RSI_14'] = ta.rsi(df['Close'], length=14)
    df['RSI_6'] = ta.rsi(df['Close'], length=6)
    df['RSI_5'] = ta.rsi(df['Close'], length=5)

    ## Stochastic Oscillator
    stoch = ta.stoch(df['High'], df['Low'], df['Close'])
    df['%K'] = stoch['STOCHk_14_3_3']
    df['%D'] = stoch['STOCHd_14_3_3']

    # 2. Trend Indicators
    ## Simple Moving Average (SMA)
    df['SMA5'] = ta.sma(df['Close'], length=5)
    df['SMA10'] = ta.sma(df['Close'], length=10)

    ## MACD (fast, slow, and signal periods)
    macd = ta.macd(df['Close'])
    df['MACD_Line'] = macd['MACD_12_26_9']
    df['MACD_Histogram'] = macd['MACDh_12_26_9']
    df['Signal_Line'] = macd['MACDs_12_26_9']

    # 3. Volatility Indicators
    ## Bollinger Bands
    bband = ta.bbands(df['Close'])
    df['Lower_BB'] = bband['BBL_5_2.0']
    df['Middle_BB'] = bband['BBM_5_2.0']
    df['Upper_BB'] = bband['BBU_5_2.0']

    ## True Range
    df['True_Range'] = ta.true_range(df['High'], df['Low'], df['Close'])

    # 4. Volume Indicators
    ## Accumulation/Distribution (AD)
    df['AD'] = ta.ad(df['High'], df['Low'], df['Close'], df['Volume'])

    ## Money Flow Index (MFI)
    df['MFI'] = ta.mfi(df['High'], df['Low'], df['Close'], df['Volume'])

    ## On-Balance Volume (OBV)
    df['OBV'] = ta.obv(df['Close'], df['Volume'])

    return df


def plot_columns(df):
    # Get the number of columns
    num_columns = df.shape[1]
    
    # Determine the number of rows and columns for the subplot grid
    ncols = 2
    nrows = math.ceil(num_columns / ncols)
    
    # Create subplots with 2 plots per row
    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(12, nrows * 3))
    
    # Flatten axes to easily iterate over them, regardless of the number of rows
    axes = axes.flatten()

    # Loop through each column and plot on a separate subplot
    for i, column in enumerate(df.columns):
        axes[i].plot(df.index, df[column], label=column)
        axes[i].set_title(f'{column}')
        axes[i].set_xlabel('Index')
        axes[i].legend()
    # Remove any empty subplots (if any)
    for i in range(num_columns, len(axes)):
        fig.delaxes(axes[i])
        
    # Adjust layout for better readability
    plt.tight_layout()
    plt.show()

def plot_technical_indicators(dataset, last_days):
    plt.figure(figsize=(16, 10), dpi=100)
    shape_0 = dataset.shape[0]
    xmacd_ = shape_0 - last_days

    dataset = dataset.iloc[-last_days:, :]
    x_ = range(dataset.shape[0])
    x_ = list(dataset.index)

    plt.figure(figsize=(30, 20))

    # Plot first subplot: SMA
    plt.subplot(6, 1, 1)
    plt.plot(dataset['SMA5'], label='SMA5', linestyle='--')
    plt.plot(dataset['SMA10'], label='SMA10', linestyle='--')
    plt.plot(dataset['Close'], label='Closing Price', color='b')
    plt.title('Simple Moving Average')
    plt.ylabel('USD')
    plt.legend(loc='upper left', fontsize=8)

    # Plot second subplot: MACD
    plt.subplot(6, 1, 2)
    plt.title('MACD')
    plt.plot(dataset['MACD_Line'], label='MACD', linestyle='-.')
    plt.plot(dataset['Signal_Line'], label='Signal Line', color='r', linestyle='--')
    plt.bar(dataset.index, dataset['MACD_Histogram'], label='MACD Histogram', color='grey')
    plt.title('Moving average convergence/divergence (MACD)')
    plt.legend(loc='upper left', fontsize=8)

    # Plot third subplot: RSI
    plt.subplot(6, 1, 3)
    plt.title('Relative Strength Index (RSI)')
    plt.plot(dataset['RSI_14'], label='RSI 14', linestyle='-')
    plt.plot(dataset['RSI_6'], label='RSI 6', linestyle='-')
    plt.plot(dataset['RSI_5'], label='RSI 5', linestyle='-')
    plt.legend(loc='upper left', fontsize=8)

    # Plot fourth subplot: Stochastic Oscillator
    plt.subplot(6, 1, 4)
    plt.title('Stochastic Oscillator')
    plt.plot(dataset['%K'], label='%K', linestyle=':', color='green')
    plt.plot(dataset['%D'], label='%D', linestyle='-.', color='orange')
    plt.legend(loc='upper left', fontsize=8)

    # Plot fifth subplot: Bollinger Bands
    plt.subplot(6, 1, 5)
    plt.plot(dataset['Close'], label='Closing Price', color='b')
    plt.plot(dataset['Upper_BB'], label='Upper Band', color='c')
    plt.plot(dataset['Middle_BB'], label='Middle Band', color='r', linestyle='--')
    plt.plot(dataset['Lower_BB'], label='Lower Band', color='c')
    plt.fill_between(x_, dataset['Lower_BB'], dataset['Upper_BB'], alpha=0.35)
    plt.title('Bollinger Bands')
    plt.ylabel('USD')
    plt.legend(loc='upper left', fontsize=8)

    # Plot sixth subplot: ATR
    plt.subplot(6, 1, 6)
    plt.plot(dataset.index, dataset['True_Range'], label='True Range', color='blue')
    plt.title('Average True Range (ATR)')
    plt.xlabel('Date')
    plt.ylabel('ATR')

    # Adjust the gap between subplots
    plt.subplots_adjust(hspace=0.3)
    plt.show()

def input(df, target_column):
  # Extract the features and target
  input_X = df.loc[:, df.columns != target_column].values  # converts the df to a numpy array
  input_y = df[target_column].values
  n_features = input_X.shape[1]
  return input_X, input_y, n_features


def temporalize(X, y, lookback):
    '''
    Inputs
    X         A 2D numpy array ordered by time of shape:
              (n_observations x n_features)
    y         A 1D numpy array with indexes aligned with
              X, i.e. y[i] should correspond to X[i].
              Shape: n_observations.
    lookback  The window size to look back in the past
              records. Shape: a scalar.

    Output
    output_X  A 3D numpy array of shape:
              ((n_observations-lookback-1) x lookback x
              n_features)
    output_y  A 1D array of shape:
              (n_observations-lookback-1), aligned with X.
    '''
    output_X = []
    output_y = []
    for i in range(len(X) - lookback - 1):
        t = []
        for j in range(1, lookback + 1):
            # Gather the past records upto the lookback period
            t.append(X[[(i + j + 1)], :])
        output_X.append(t)
        output_y.append(y[i + lookback + 1])
    return np.squeeze(np.array(output_X)), np.array(output_y)

def flatten(X):
    '''
    Flatten a 3D array.

    Input
    X            A 3D array for lstm, where the array is sample x timesteps x features.

    Output
    flattened_X  A 2D array, sample x features.
    '''
    flattened_X = np.empty((X.shape[0], X.shape[2]))  # sample x features array.
    for i in range(X.shape[0]):
        flattened_X[i] = X[i, (X.shape[1]-1), :]
    return flattened_X

def split_data(X, y, DATA_SPLIT_PCT, SEED):
  X_train, X_test, y_train, y_test = train_test_split(np.array(X), np.array(y), test_size=DATA_SPLIT_PCT, shuffle = False, random_state=SEED)
  X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=DATA_SPLIT_PCT,shuffle = False, random_state=SEED)
  return X_train, X_test, X_valid, y_train, y_test, y_valid

def scale(X, scaler):
    '''
    Scale 3D array.

    Inputs
    X            A 3D array for lstm, where the array is sample x timesteps x features.
    scaler       A scaler object, e.g., sklearn.preprocessing.StandardScaler, sklearn.preprocessing.normalize

    Output
    X            Scaled 3D array.
    '''
    for i in range(X.shape[0]):
        X[i, :, :] = scaler.transform(X[i, :, :])

    return X

def val_inspection(history, model, X_valid_scaled, y_valid):
    plt.figure(figsize=(30, 20))

    # Plot first subplot: Loss and Validation Loss
    plt.subplot(3, 1, 1)
    plt.plot(history['loss'], label='Training Loss')
    plt.plot(history['val_loss'], label='Validation Loss')
    plt.title('Model Loss over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend(loc='upper left')
    plt.grid(True)

    # Plot second subplot: Root Mean Squared Error and Validation RMSE
    plt.subplot(3, 1, 2)
    plt.plot(history['root_mean_squared_error'], label='Training RMSE')
    plt.plot(history['val_root_mean_squared_error'], label='Validation RMSE')
    plt.title('Model RMSE over Epochs')
    plt.xlabel('Epochs')
    plt.ylabel('Root Mean Squared Error')
    plt.legend(loc='upper left')
    plt.grid(True)

    # Plot third subplot: Validation Predictions vs Observations
    val_prediction = model.predict(X_valid_scaled)
    y_val_series = pd.Series(y_valid.flatten())
    y_val_prediction_series = pd.Series(val_prediction.flatten())
    plt.subplot(3, 1, 3)
    plt.plot(y_val_series, label='Observation', color='blue')
    plt.plot(y_val_prediction_series, label='Prediction', color='red', linestyle='--')
    plt.xlabel('Index')
    plt.ylabel('Values')
    plt.title('Validation Predictions vs. Observations')
    plt.legend(loc='upper left')
    plt.grid(True)

    plt.subplots_adjust(hspace=0.3)
    plt.show()

def evaluate_prediction(predictions, actual, model_name):
    errors = predictions - actual
    mse = np.square(errors).mean()
    rmse = np.sqrt(mse)
    mae = np.abs(errors).mean()
    print(model_name + ':')
    print('Mean Absolute Error: {:.4f}'.format(mae))
    print('Root Mean Square Error: {:.4f}'.format(rmse))
    print('')
    return mae, rmse

def test_inspection(model, X_test_scaled, y_test, model_name):
  # Generate predictions
  predictions = model.predict(X_test_scaled)
  # Calculate R-squared
  r2 = r2_score(y_test, predictions)
  print("Out-of-sample R-squared:", np.round(r2,2))
  # Print evaluation result
  evaluation = evaluate_prediction(predictions, y_test, model_name)
  # Plot
  plt.figure(figsize=(20,7))
  # Actual values
  plt.plot(y_test, color='blue', label='Actual Values')
  # Predicted values
  plt.plot(predictions, color='red', linestyle='--', label='Predicted Values')
  # Adding titles and labels
  plt.title('Actual vs Predicted Values {}'.format(model_name))
  plt.xlabel('Index')
  plt.ylabel('Value')
  plt.legend(loc='upper left')
  plt.grid(True)
  # Show plot
  plt.show()
  return predictions

# Souce: https://github.com/jiewwantan/RNN_LSTM_trading_model/blob/master/rnn_bactesting.ipynb
def prediction_result_plot(original, trained, valid, test, nn):

    """
    Function to plot all portfolio cumulative returns
    """
    # Set a palette so that all 14 lines can be better differentiated
    color_palette = ['#e6194b', '#3cb44b', '#4363d8','#bcbd22']
    fig, ax = plt.subplots(figsize=(20, 8))
    ax.plot(original.index, original, '-', label="Original price", linewidth=2, color=color_palette[0])
    ax.plot(trained.index, trained['Train_Prediction'], '-', label="Trained price", linewidth=2,
            color=color_palette[1], alpha=0.8)
    ax.plot(valid.index, valid['Valid_Prediction'], '-', label="Validation price", linewidth=2,
            color=color_palette[2])
    ax.plot(test.index, test['Test_Prediction'], '-', label="Test price", linewidth=2,
            color=color_palette[3])
    plt.legend()
    plt.xlabel('Date')
    plt.ylabel('Stock price')
    plt.title('Original, trained & predicted stock price trained on {} model'.format(nn))
    plt.grid(True)
    plt.subplots_adjust(hspace=0.5)

def final_visualization(df, lookback, DATA_SPLIT_PCT, SEED, model, X_train_scaled, X_valid_scaled, predictions, original_column, model_name):
  df_index = pd.DataFrame()
  df_index['Date'] = df.index.values
  X_time_index, y_time_index = temporalize(X = df_index.values, y = df_index.values, lookback = lookback)

  # Split into train, valid, and test
  X_train_time_index, X_test_time_index, X_valid_time_index, y_train_time_index, y_test_time_index, y_valid_time_index = split_data(X_time_index, y_time_index, DATA_SPLIT_PCT, SEED)

  # Prediction on y
  y_train_pred = model.predict(X_train_scaled)
  y_valid_pred = model.predict(X_valid_scaled)
  y_test_pred = predictions

  # Create DataFrame
  train_prediction_df = pd.DataFrame(
    data=y_train_pred,
    index=y_train_time_index.flatten(),
    columns=['Train_Prediction'])

  valid_prediction_df = pd.DataFrame(
    data=y_valid_pred,
    index=y_valid_time_index.flatten(),
    columns=['Valid_Prediction'])

  test_prediction_df = pd.DataFrame(
    data=y_test_pred,
    index=y_test_time_index.flatten(),
    columns=['Test_Prediction'])

  # Plot all predictions
  prediction_result_plot(
    original_column,
    train_prediction_df,
    valid_prediction_df,
    test_prediction_df,
    model_name)
  
  return test_prediction_df


# LSTM Model
def lstm_model(input_shape, output_units):
    output = 1
    model = Sequential()
    model.add(Input(shape=input_shape, name='input'))

    # LSTM layers
    model.add(LSTM(units=16, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='lstm_layer_1'))
    model.add(Dropout(0.5))
    model.add(LSTM(units=8, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='lstm_layer_2'))
    model.add(Flatten())
    model.add(Dropout(0.5))

    # Output layer
    model.add(Dense(units=output_units, activation='linear', name='output'))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])
    model.summary()
    return model

def fit_model(model, X_train_scaled, y_train, X_valid_scaled, y_valid):
    stop_early = tf.keras.callbacks.EarlyStopping(monitor="val_loss", mode="min", verbose=0, patience=30, restore_best_weights=True)
    history = model.fit(X_train_scaled, y_train,
                        epochs = 100, batch_size = 32,
                        validation_data=(X_valid_scaled , y_valid),
                        shuffle = False,verbose=0, callbacks=[stop_early]).history
    return history

# Define the HyperModel class for LSTM
class LSTMHyperModel(HyperModel):
    def __init__(self, input_shape, output_units):
        self.input_shape = input_shape
        self.output_units = output_units

    def build(self, hp):
        # Input layer
        model = Sequential()
        model.add(Input(shape=self.input_shape,name='input'))

        # Add the first LSTM layer
        model.add(LSTM(units=hp.Int('lstm_layer_1', min_value=1,max_value=100,step=2),
                  activation="relu",
                   return_sequences=True,
                   recurrent_dropout=0.5))
        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the subsequent LSTM layers,
        model.add(LSTM(units=hp.Int('lstm_layer_2', min_value=1,max_value=100,step=2),
                  activation="relu",
                   return_sequences=True,
                   recurrent_dropout=0.5))
        model.add(Flatten())
        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the output layer
        model.add(Dense(units=self.output_units, activation='linear', name='output'))

        # Compile the model
        model.compile(loss='mean_squared_error', metrics=[RootMeanSquaredError()], optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])))

        return model

def bayesian_opt_tuner(build_model, X_train_scaled, y_train, X_valid_scaled, y_valid):
  bayesian_opt_tuner = BayesianOptimization(
    build_model,
    objective=kt.Objective("val_loss", direction="min"),
    max_trials=3,
    executions_per_trial=1,
    directory="keras_tuning",
    project_name='kerastuner_bayesian',
    overwrite=True)

  # Peform search
  stop_early = tf.keras.callbacks.EarlyStopping(monitor="val_loss", mode="min", verbose=0, patience=30,restore_best_weights=True)
  bayesian_opt_tuner.search(X_train_scaled, y_train, batch_size=32, epochs=100, validation_data=(X_valid_scaled, y_valid), verbose=0, callbacks=[stop_early])
  # Retrieve best hyperparameter
  best_hyperparameters = bayesian_opt_tuner.get_best_hyperparameters(num_trials=1)[0]
  model = bayesian_opt_tuner.hypermodel.build(best_hyperparameters)
  print('The best hyperparameters are \n', best_hyperparameters.values)
  print(model.summary())
  return model

# BiLSTM
def bi_lstm_model(input_shape, output_units):
    model = Sequential()
    model.add(Input(shape=input_shape, name='input'))

    # LSTM layers
    model.add(Bidirectional(LSTM(units=16, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='bi_lstm_layer_1')))
    model.add(Dropout(0.5))
    model.add(Bidirectional(LSTM(units=8, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='bi_lstm_layer_2')))
    model.add(Flatten())
    model.add(Dropout(0.5))

    # Output layer
    model.add(Dense(units=output_units, activation='linear', name='output'))

    # Compile the model
    model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])
    model.summary()
    return model

# Define the HyperModel class for BILSTM
class BILSTMHyperModel(HyperModel):
    def __init__(self, input_shape, output_units):
        self.input_shape = input_shape
        self.output_units = output_units

    def build(self, hp):
        # Input layer
        model = Sequential()
        model.add(Input(shape=self.input_shape,name='input'))

        # Add the first BILSTM layer
        model.add(Bidirectional(LSTM(units=hp.Int('bi_lstm_layer_1', min_value=1,max_value=100,step=2),
                  activation="relu",
                  return_sequences=True,
                  recurrent_dropout=0.5)))
        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the subsequent BILSTM layers,
        model.add(Bidirectional(LSTM(units=hp.Int('bi_lstm_layer_2', min_value=1,max_value=100,step=2),
                  activation="relu",
                  return_sequences=True,
                  recurrent_dropout=0.5)))
        model.add(Flatten())
        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the output layer
        model.add(Dense(units=self.output_units, activation='linear', name='output'))

        # Compile the model
        model.compile(loss='mean_squared_error', metrics=[RootMeanSquaredError()], optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])))

        return model

# GRU
def gru_model(input_shape, output_units):
  model = Sequential()
  model.add(Input(shape=input_shape, name='input'))

  # First GRU layer with dropout
  model.add(GRU(units = 16, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='gru_layer_1'))
  model.add(Dropout(0.5))
  # Second GRU layer
  model.add(GRU(units = 8, activation='relu', return_sequences=True, recurrent_dropout=0.5, name='gru_layer_2'))
  model.add(Flatten())
  model.add(Dropout(0.5))

  # Output layer
  model.add(Dense(units = output_units, activation='linear', name='output'))
  model.compile(optimizer='adam', loss='mean_squared_error', metrics=[RootMeanSquaredError()])
  model.summary()
  return model

# Define the HyperModel class for GRU
class GRUHyperModel(HyperModel):
    def __init__(self, input_shape, output_units):
        self.input_shape = input_shape
        self.output_units = output_units

    def build(self, hp):
        # Input layer
        model = Sequential()
        model.add(Input(shape=self.input_shape,name='input'))

        # Add the first GRU layer
        model.add(GRU(units=hp.Int('gru_layer_1', min_value=1,max_value=100,step=2),
                  activation="relu",
                  return_sequences=True,
                  recurrent_dropout=0.5))
        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the subsequent layers
        model.add(GRU(units=hp.Int('gru_layer_2', min_value=1,max_value=100,step=2),
                  activation="relu",
                  return_sequences=True,
                  recurrent_dropout=0.5))
        model.add(Flatten())
        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.2, max_value=0.5, step=0.1)))

        # Add the output layer
        model.add(Dense(units=self.output_units, activation='linear', name='output'))

        # Compile the model
        model.compile(loss='mean_squared_error', metrics=[RootMeanSquaredError()], optimizer=keras.optimizers.Adam(hp.Choice('learning_rate',values=[1e-1, 1e-2, 1e-3, 1e-4, 1e-5])))

        return model

def generate_signals(df, column, target='long_only'):
    # Create a copy of the original DataFrame
    df_copy = df.copy()

    # Initialize the 'Strategy' column in the copy
    df_copy['Strategy'] = 0

    # Shift predictions to compare t+1 with t
    price_t = df_copy[column]
    price_t1 = df_copy[column].shift(-1)  # Shift by 1 to compare t+1 prices

    if target == 'long_only':
        # Long position (1) when price_t1 > price_t, otherwise no position (0)
        df_copy['Strategy'] = np.where(price_t1 > price_t, 1, 0)

    elif target == 'long_short':
        # Long position (1) when price_t1 > price_t, Short position (-1) when price_t1 < price_t
        df_copy['Strategy'] = np.where(price_t1 > price_t, 1, -1)

    # Return the DataFrame with strategies applied
    return df_copy


def plot_strategy_signals(df, title, strategy='long_only'):
    """
    Plots Test_Prediction values and overlays Strategy signals.

    Parameters:
    df (pd.DataFrame): DataFrame with 'Observation' and 'Long_Short' & 'Long_Only' columns.
                       The index should be of type datetime.

    Returns:
    None
    """
    plt.figure(figsize=(14, 7))

    # Plot Test_Prediction
    plt.plot(df.index, df['Observation'], label='Real Close Price', color='blue')

    # Plot Strategy signals
    long_signals = df[df['Long_Short'] == 1.0]
    hold_signals = df[df['Long_Only'] == 0.0]
    short_signals = df[df['Long_Short'] == -1.0]

    if strategy =='long_only':
      plt.scatter(long_signals.index, long_signals['Observation'], marker='^', color='green', label='Long Signal', alpha=1)
      plt.scatter(hold_signals.index, hold_signals['Observation'], marker='o', color='red', label='No Signal', alpha=0.5)

    elif strategy == 'long_short':
      plt.scatter(long_signals.index, long_signals['Observation'], marker='^', color='green', label='Long Signal', alpha=1)
      plt.scatter(short_signals.index, short_signals['Observation'], marker='v', color='red', label='Short Signal', alpha=1)

    # Formatting
    plt.title(f'Test Prediction with {title} Strategy Signals')
    plt.xlabel('Date')
    plt.ylabel('Test Prediction')
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()

    # Show the plot
    plt.savefig('strategy.png', dpi=300)
    plt.show()

def plot_technical_signals(df, observation, signal, title):
    plt.figure(figsize=(20, 7))

    # Plot predicted returns
    plt.plot(df.index, df[observation], label='Close Price', color='blue', linestyle='-')

    # Plot trading signals
    buy_signals = df[df[signal] == 1]
    sell_signals = df[df[signal] == -1]

    plt.scatter(buy_signals.index, buy_signals[observation], color='green', label='Buy Signal', marker='^', s=20)
    plt.scatter(sell_signals.index, sell_signals[observation], color='red', label='Sell Signal', marker='v', s=20)

    # Set labels and title
    plt.xlabel('Date')
    plt.ylabel('Close Price')
    plt.title(f'Trading Signals Based on {title}')
    plt.legend()
    plt.grid(True)
    plt.savefig('technical_signals.png', dpi=300)
    plt.show()


# Define function to calculate adjusted returns based on strategy signals
def calculate_adjusted_return(df, signal_column, target_column):
    return np.where(df[signal_column] == 1, df[target_column],
                    np.where(df[signal_column] == -1, -df[target_column], 0))

def calculate_portfolio_values(df, start_money=1000):
    """
    Calculate portfolio values for various trading strategies.

    Parameters:
    df (pd.DataFrame): DataFrame with columns 'Test_Prediction', 'Long_Only', 'Long_Short',
                       'Observation', 'Buy_Hold', 'MACD_Trading_Signal'.
    start_money (float): Initial investment amount.

    Returns:
    pd.DataFrame: DataFrame with calculated portfolio values for each strategy.
    """
    df = df.copy()

    # Calculate daily returns
    df['Return'] = df['Observation'].pct_change().fillna(0)

    # Buy-and-Hold Portfolio Value
    df['Buy_Hold_Cumulative_Return'] = (1 + df['Return']).cumprod()
    df['Portfolio_Value_Buy_Hold'] = start_money * df['Buy_Hold_Cumulative_Return']

    # Long-Only Portfolio Value
    df['Long_Only_Return'] = df['Return'] * df['Long_Only']
    df['Long_Only_Cumulative_Return'] = (1 + df['Long_Only_Return']).cumprod()
    df['Portfolio_Value_Long_Only'] = start_money * df['Long_Only_Cumulative_Return']

    # Long-Short Portfolio Value
    # Adjust returns for short selling:
    # If Long_Short is -1 (short), the return is inverted.
    df['Long_Short_Return'] = np.where(df['Long_Short'] == 1, df['Return'],
                                       np.where(df['Long_Short'] == -1, -df['Return'],0))
    df['Long_Short_Cumulative_Return'] = (1 + df['Long_Short_Return']).cumprod()
    df['Portfolio_Value_Long_Short'] = start_money * df['Long_Short_Cumulative_Return']

    # MACD Trading Strategy Portfolio Value
    # MACD_Trading_Signal = 1 for long, -1 for short
    df['MACD_Trading_Return'] = np.where(df['MACD_Trading_Signal'] == 1, df['Return'],
                                         np.where(df['MACD_Trading_Signal'] == -1, -df['Return'],0))
    df['MACD_Trading_Cumulative_Return'] = (1 + df['MACD_Trading_Return']).cumprod()
    df['Portfolio_Value_MACD_Trading'] = start_money * df['MACD_Trading_Cumulative_Return']

    return df[['Return','Long_Only_Return','Long_Short_Return','MACD_Trading_Return','Portfolio_Value_Buy_Hold', 'Portfolio_Value_Long_Only', 'Portfolio_Value_Long_Short', 'Portfolio_Value_MACD_Trading']]

def plot_portfolio_values(df):
    """
    Plots portfolio values for various trading strategies.

    Parameters:
    df (pd.DataFrame): DataFrame with portfolio values for different strategies.

    Returns:
    None
    """
    plt.figure(figsize=(14, 7))

    # Plot Buy-and-Hold Portfolio Value
    plt.plot(df.index, df['Portfolio_Value_Buy_Hold'], label='Buy-and-Hold Portfolio Value', color='blue')

    # Plot Long-Only Portfolio Value
    plt.plot(df.index, df['Portfolio_Value_Long_Only'], label='Long-Only Portfolio Value', color='green')

    # Plot Long-Short Portfolio Value
    plt.plot(df.index, df['Portfolio_Value_Long_Short'], label='Long-Short Portfolio Value', color='red')

    # Plot MACD Trading Portfolio Value
    plt.plot(df.index, df['Portfolio_Value_MACD_Trading'], label='MACD Trading Portfolio Value', color='purple')

    # Formatting the plot
    plt.title('Portfolio Value Comparison for Different Strategies')
    plt.xlabel('Date')
    plt.ylabel('Portfolio Value ($)')
    plt.legend()
    plt.grid(True)
    plt.xticks(rotation=45)
    plt.tight_layout()

    # Show the plot
    plt.savefig('portfoliovalue.png', dpi=300)
    plt.show()